<!-- This project is forked from WeClone (https://github.com/xming521/WeClone) -->
<!-- æœ¬é¡¹ç›®ä» WeClone (https://github.com/xming521/WeClone) fork è€Œæ¥ -->

# WeClone ä½¿ç”¨æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

WeClone æä¾›äº†å®Œæ•´çš„å‘½ä»¤è¡Œç•Œé¢æ¥å¤„ç†ä»æ•°æ®å‡†å¤‡åˆ°æ¨¡å‹éƒ¨ç½²çš„æ•´ä¸ªæµç¨‹ã€‚æ‰€æœ‰å‘½ä»¤éƒ½é€šè¿‡ `weclone-cli` è°ƒç”¨ã€‚

### åŸºæœ¬è¯­æ³•
```bash
weclone-cli [COMMAND] [OPTIONS]
```

## ğŸ“ å¯ç”¨å‘½ä»¤åˆ—è¡¨

### 1. `make-dataset` - æ•°æ®é›†ç”Ÿæˆ
**åŠŸèƒ½**: å¤„ç†èŠå¤©è®°å½•CSVæ–‡ä»¶ï¼Œç”Ÿæˆé—®ç­”å¯¹æ•°æ®é›†
```bash
weclone-cli make-dataset
```
- è¯»å– `./dataset/csv/` ç›®å½•ä¸‹çš„èŠå¤©è®°å½•æ–‡ä»¶
- ç”Ÿæˆè®­ç»ƒç”¨çš„é—®ç­”å¯¹æ•°æ®é›†
- æ”¯æŒéšç§ä¿¡æ¯è¿‡æ»¤å’Œæ•°æ®æ¸…æ´—
- é…ç½®å‚æ•°åœ¨ `settings.jsonc` çš„ `make_dataset_args` ä¸­è®¾ç½®

### 2. `train-sft` - æ¨¡å‹å¾®è°ƒ
**åŠŸèƒ½**: ä½¿ç”¨å‡†å¤‡å¥½çš„æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒ
```bash
weclone-cli train-sft
```
- åŸºäºLLaMA Factoryè¿›è¡ŒLoRAå¾®è°ƒ
- æ”¯æŒå•å¡/å¤šå¡è®­ç»ƒ
- è®­ç»ƒå‚æ•°åœ¨ `settings.jsonc` çš„ `train_sft_args` ä¸­é…ç½®

### 3. `export-to-gguf` - æ¨¡å‹å¯¼å‡º
**åŠŸèƒ½**: å°†LoRAå¾®è°ƒæ¨¡å‹å¯¼å‡ºä¸ºGGUFæ ¼å¼ï¼Œç”¨äºOllamaéƒ¨ç½²
```bash
weclone-cli export-to-gguf
```
- è‡ªåŠ¨åˆå¹¶LoRA adapterå’ŒåŸºç¡€æ¨¡å‹
- è½¬æ¢ä¸ºGGUFæ ¼å¼å¹¶æ”¯æŒé‡åŒ–
- ç”ŸæˆWindows Ollamaéƒ¨ç½²åŒ…
- åŒ…å«Modelfileå’Œéƒ¨ç½²è„šæœ¬
- **ä¾èµ–**: éœ€è¦å®‰è£… llama.cpp å·¥å…·
- **è¯¦ç»†æŒ‡å—**: è¯·å‚è€ƒ [GGUFå¯¼å‡ºæŒ‡å—](docs/GGUF_EXPORT_GUIDE.md)

### 4. `webchat-demo` - Webç•Œé¢æµ‹è¯•
**åŠŸèƒ½**: å¯åŠ¨ Web UI ä¸å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œäº¤äº’æµ‹è¯•
```bash
weclone-cli webchat-demo
```
- æä¾›å‹å¥½çš„Webç•Œé¢è¿›è¡Œå¯¹è¯æµ‹è¯•
- å¯è°ƒæ•´ temperatureã€top_p ç­‰æ¨ç†å‚æ•°
- ç”¨äºéªŒè¯å¾®è°ƒæ•ˆæœ

### 5. `server` - APIæœåŠ¡
**åŠŸèƒ½**: å¯åŠ¨APIæœåŠ¡ï¼Œæä¾›æ¨¡å‹æ¨ç†æ¥å£
```bash
weclone-cli server
```
- å¯åŠ¨OpenAIå…¼å®¹çš„APIæœåŠ¡
- é»˜è®¤ç›‘å¬ `http://127.0.0.1:8005/v1`
- æ”¯æŒèŠå¤©æœºå™¨äººé›†æˆ

### 6. `test-model` - æ¨¡å‹æµ‹è¯•
**åŠŸèƒ½**: ä½¿ç”¨å¸¸è§èŠå¤©é—®é¢˜æµ‹è¯•æ¨¡å‹æ€§èƒ½
```bash
weclone-cli test-model
```
- ä½¿ç”¨é¢„å®šä¹‰çš„æµ‹è¯•é—®é¢˜é›†è¯„ä¼°æ¨¡å‹
- ç”Ÿæˆæµ‹è¯•ç»“æœæŠ¥å‘Š `test_result-my.txt`
- **æ³¨æ„**: éœ€è¦å…ˆå¯åŠ¨ `server` å‘½ä»¤

### 7. `eval-framework` - ç»¼åˆè¯„ä¼°æ¡†æ¶
**åŠŸèƒ½**: è¿è¡Œå¤šç»´åº¦ã€å¤šæŒ‡æ ‡çš„å…¨é¢æ¨¡å‹è¯„ä¼°
```bash
weclone-cli eval-framework --config <é…ç½®æ–‡ä»¶è·¯å¾„>
```

**å‚æ•°è¯´æ˜**:
- `--config, -c`: è¯„ä¼°é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
  - æ”¯æŒ YAML å’Œ JSON æ ¼å¼
  - ç¤ºä¾‹: `weclone/eval/config/simple_test.yaml`

**è¯„ä¼°æŒ‡æ ‡**:
- **äº’åŠ¨æµç•…åº¦**: ä¸­æ–­æ¬¡æ•°ã€è¶…æ—¶é‡å‘ã€å¹³å‡è½®æ¬¡é—´éš”
- **æƒ…æ„Ÿæ»¡æ„åº¦**: èŠå¤©åè¯„åˆ†ã€æƒ…æ„Ÿåˆ†æ•°
- **ä»»åŠ¡æˆåŠŸç‡**: æ£€ç´¢ç²¾åº¦ã€ç”Ÿæˆè´¨é‡ã€å‡½æ•°è°ƒç”¨å‡†ç¡®æ€§
- **å»¶è¿Ÿæ€§èƒ½**: é¦–tokenæ—¶é—´ã€å®Œæ•´å“åº”æ—¶é—´ã€ååé‡
- **æˆæœ¬åˆ†æ**: tokenä½¿ç”¨é‡ã€USDæˆæœ¬ã€æˆæœ¬æ•ˆç‡

**è¾“å‡ºç»“æœ**:
- ä¿å­˜åˆ° `eval_runs/<æ—¶é—´æˆ³>/` ç›®å½•
- åŒ…å«è¯¦ç»†çš„CSVæ•°æ®å’Œè¿è¡Œå…ƒæ•°æ®
- æ˜¾ç¤ºå¹³å‡æŒ‡æ ‡æ‘˜è¦

### 8. `eval-model` - éªŒè¯é›†è¯„ä¼° 
**åŠŸèƒ½**: ä½¿ç”¨ä»è®­ç»ƒæ•°æ®ä¸­åˆ’åˆ†å‡ºæ¥çš„éªŒè¯é›†è¿›è¡Œè¯„ä¼°
```bash
weclone-cli eval-model
```
- ç”¨äºæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ€§èƒ½ç›‘æ§
- åŸºäºéªŒè¯é›†æ•°æ®è¯„ä¼°æ¨¡å‹æ•ˆæœ

## ğŸ”¬ è¯„ä¼°æ¡†æ¶æ¶æ„

WeClone æä¾›äº†åŠŸèƒ½å¼ºå¤§çš„æ¨¡å—åŒ–è¯„ä¼°æ¡†æ¶ï¼Œæ”¯æŒå¯¹ä»»ä½• OpenAI å…¼å®¹çš„æ¨¡å‹è¿›è¡Œå…¨é¢çš„å¤šç»´åº¦è¯„ä¼°ã€‚

### æ¡†æ¶ç‰¹æ€§

- **ğŸ”§ æ¨¡å—åŒ–åŸºå‡†ç³»ç»Ÿ**: æ¯ä¸ªåŸºå‡†éƒ½æ˜¯ç‹¬ç«‹çš„å¯é…ç½®æ¨¡å—
- **ğŸ“Š å¤šæŒ‡æ ‡è¯„ä¼°**: äº¤äº’æµç•…åº¦ã€æƒ…æ„Ÿæ»¡æ„åº¦ã€ä»»åŠ¡æˆåŠŸç‡ã€å»¶è¿Ÿæ€§èƒ½ã€æˆæœ¬åˆ†æ
- **âš™ï¸ çµæ´»é…ç½®**: æ”¯æŒ YAML/JSON é…ç½®æ–‡ä»¶
- **ğŸ’¾ æ•°æ®æŒä¹…åŒ–**: ç»“æ„åŒ– CSV è¾“å‡ºï¼Œæ—¶é—´æˆ³æ ‡è®°çš„è¿è¡Œè®°å½•
- **ğŸŒ å¤šæ¨¡å‹æ”¯æŒ**: åŒæ—¶æµ‹è¯•å¤šä¸ªæ¨¡å‹å’Œæç¤ºå˜ä½“
- **ğŸ› è°ƒè¯•æ¨¡å¼**: é™åˆ¶æµ‹è¯•æ¡ˆä¾‹æ•°é‡ï¼Œå¿«é€Ÿè¿­ä»£å¼€å‘

### æ”¯æŒçš„æ¨¡å‹ç±»å‹

è¯„ä¼°æ¡†æ¶æ”¯æŒä»»ä½• OpenAI å…¼å®¹çš„ APIï¼ŒåŒ…æ‹¬ï¼š

- **æœ¬åœ°æ¨¡å‹**: WeClone å¾®è°ƒåçš„æ¨¡å‹ (`http://127.0.0.1:8005/v1`)
- **OpenAI æ¨¡å‹**: GPT-3.5, GPT-4 ç­‰ (`https://api.openai.com/v1`)
- **ç¬¬ä¸‰æ–¹ API**: OpenRouterã€Anthropic ä»£ç†ç­‰
  - DeepSeek: `https://openrouter.ai/api/v1`
  - é€šä¹‰åƒé—®: `https://dashscope.aliyuncs.com/compatible-mode/v1`
  - æ™ºè°± GLM: `https://open.bigmodel.cn/api/paas/v4`
- **è‡ªéƒ¨ç½²æ¨¡å‹**: vLLMã€FastChatã€Ollama ç­‰å…¼å®¹æœåŠ¡

### è¯„ä¼°åŸºå‡†è¯¦æƒ…

#### 1. äº¤äº’æµç•…åº¦ (`interaction_fluency`)
- **ä¸­æ–­è®¡æ•°**: å¯¹è¯ä¸­çš„ä¸­æ–­æ¬¡æ•°
- **è¶…æ—¶é‡å‘**: å“åº”è¶…æ—¶å¯¼è‡´çš„é‡å‘æ¬¡æ•°  
- **å¹³å‡è½®æ¬¡é—´éš”**: ç”¨æˆ·-åŠ©æ‰‹è½®æ¬¡ä¹‹é—´çš„å¹³å‡æ—¶é—´é—´éš”

#### 2. æƒ…æ„Ÿæ»¡æ„åº¦ (`sentiment_satisfaction`)
- **èŠå¤©åè¯„åˆ†**: 1-5 åˆ†çš„ä¸»è§‚æ»¡æ„åº¦è¯„åˆ†
- **æƒ…æ„Ÿåˆ†æ•°**: -1 åˆ° 1 çš„æƒ…æ„Ÿææ€§åˆ†æ

#### 3. ä»»åŠ¡æˆåŠŸç‡ (`task_success`)
- **æ£€ç´¢ç²¾åº¦**: ä¿¡æ¯æ£€ç´¢çš„å‡†ç¡®æ€§
- **ç”Ÿæˆè´¨é‡**: BLEU åˆ†æ•°ç­‰ç”Ÿæˆè´¨é‡æŒ‡æ ‡
- **å‡½æ•°è°ƒç”¨å‡†ç¡®æ€§**: å·¥å…·ä½¿ç”¨çš„æ­£ç¡®ç‡

#### 4. å»¶è¿Ÿæ€§èƒ½ (`latency`)
- **é¦– Token æ—¶é—´**: é¦–ä¸ª Token ç”Ÿæˆå»¶è¿Ÿ
- **å®Œæ•´å“åº”æ—¶é—´**: å®Œæˆæ•´ä¸ªå“åº”çš„æ—¶é—´
- **ååé‡**: æ¯ç§’ Token ç”Ÿæˆæ•°é‡

#### 5. æˆæœ¬åˆ†æ (`cost`)
- **Token ä½¿ç”¨é‡**: è¾“å…¥å’Œè¾“å‡º Token ç»Ÿè®¡
- **USD æˆæœ¬**: åŸºäºæ¨¡å‹å®šä»·çš„æˆæœ¬è®¡ç®—
- **æˆæœ¬æ•ˆç‡**: æ¯ Token æˆæœ¬åˆ†æ

### é…ç½®ç¤ºä¾‹

#### åŸºç¡€é…ç½®
```yaml
batch_name: "model_comparison_test"

# æç¤ºé…ç½®
prompts:
  - id: "default_system"
    version: "v1.0" 
    content: "ä½ æ˜¯ä¸€ä¸ªå‹å–„ã€æœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"

# æ¨¡å‹é…ç½® - æ”¯æŒå¤šç§ API
models:
  # æœ¬åœ°å¾®è°ƒæ¨¡å‹
  - name: "weclone:local"
    params:
      model: "gpt-3.5-turbo"
      temperature: 0.7
      max_tokens: 150
    host: "http://127.0.0.1:8005/v1"
    api_key: "sk-test"
    
  # OpenRouter DeepSeek
  - name: "deepseek:chat-v3"
    params:
      model: "deepseek/deepseek-chat-v3-0324"
      temperature: 0.7
      max_tokens: 150
    host: "https://openrouter.ai/api/v1"
    api_key: "${OPENROUTER_API_KEY}"
    
  # OpenAI å®˜æ–¹
  - name: "openai:gpt-4"
    params:
      model: "gpt-4"
      temperature: 0.7
      max_tokens: 150
    host: "https://api.openai.com/v1"
    api_key: "${OPENAI_API_KEY}"

# æµ‹è¯•æ•°æ®
cases:
  - file: "dataset/test_data.json"

# å¯ç”¨çš„è¯„ä¼°æŒ‡æ ‡
metrics:
  - interaction_fluency
  - sentiment_satisfaction  
  - task_success
  - latency
  - cost

# æ‰§è¡Œè®¾ç½®
parallel: 2
max_usd: 10.0
timeout_seconds: 60
```

#### é«˜çº§åŸºå‡†é…ç½®
```yaml
# åŸºå‡†æ¨¡å—è‡ªå®šä¹‰é…ç½®
benchmark_configs:
  interaction_fluency:
    interrupt_threshold_ms: 300
    timeout_threshold_ms: 25000
    
  sentiment_satisfaction:
    positive_words: ["å¥½", "æ£’", "æ»¡æ„", "å–œæ¬¢"]
    negative_words: ["å·®", "ç³Ÿç³•", "ä¸æ»¡", "è®¨åŒ"] 
    base_rating: 3.5
    rating_sensitivity: 0.8
    
  cost:
    model_pricing:
      "gpt-4":
        prompt: 0.03
        completion: 0.06
      "deepseek/deepseek-chat-v3-0324":
        prompt: 0.0014
        completion: 0.0028
    excellent_cost_per_token: 0.000005
```

### ä½¿ç”¨æ–¹å¼

#### å‘½ä»¤è¡Œè¯„ä¼°
```bash
# è¿è¡Œè¯„ä¼°
weclone-cli eval-framework --config weclone/eval/config/deepseek_openrouter_test.yaml

# è°ƒè¯•æ¨¡å¼ï¼ˆé™åˆ¶æµ‹è¯•æ¡ˆä¾‹ï¼‰
weclone-cli eval-framework --config weclone/eval/config/debug_test.yaml
```

#### ç¯å¢ƒå˜é‡é…ç½®
```bash
# è®¾ç½® API å¯†é’¥
export OPENROUTER_API_KEY="your_openrouter_key"
export OPENAI_API_KEY="your_openai_key"
export DASHSCOPE_API_KEY="your_qwen_key"
```

## ğŸ“‹ é…ç½®æ ¼å¼è¯¦ç»†è¯´æ˜

### é…ç½®æ–‡ä»¶ç»“æ„

è¯„ä¼°é…ç½®æ–‡ä»¶æ”¯æŒ **YAML** å’Œ **JSON** æ ¼å¼ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

```yaml
# åŸºæœ¬ä¿¡æ¯
batch_name: "string"           # è¯„ä¼°æ‰¹æ¬¡åç§° (å¿…å¡«)

# æ ¸å¿ƒé…ç½®éƒ¨åˆ†
prompts: []                    # æç¤ºè¯é…ç½®åˆ—è¡¨ (å¿…å¡«)
models: []                     # æ¨¡å‹é…ç½®åˆ—è¡¨ (å¿…å¡«)  
cases: []                      # æµ‹è¯•æ•°æ®é…ç½®åˆ—è¡¨ (å¿…å¡«)
metrics: []                    # è¯„ä¼°æŒ‡æ ‡åˆ—è¡¨ (å¿…å¡«)

# å¯é€‰é…ç½®éƒ¨åˆ†
benchmark_configs: {}          # åŸºå‡†æ¨¡å—è‡ªå®šä¹‰é…ç½® (å¯é€‰)
debug: {}                      # è°ƒè¯•æ¨¡å¼é…ç½® (å¯é€‰)
parallel: int                  # å¹¶å‘æ•° (å¯é€‰, é»˜è®¤: 1)
max_usd: float                 # æœ€å¤§æˆæœ¬é™åˆ¶ (å¯é€‰, é»˜è®¤: æ— é™åˆ¶)
timeout_seconds: int           # è¯·æ±‚è¶…æ—¶æ—¶é—´ (å¯é€‰, é»˜è®¤: 30)
output_formats: []             # è¾“å‡ºæ ¼å¼åˆ—è¡¨ (å¯é€‰)
```

### æ ¸å¿ƒé…ç½®å‚æ•°

#### 1. `prompts` - æç¤ºè¯é…ç½®
å®šä¹‰ç³»ç»Ÿæç¤ºè¯å’Œå¯¹è¯è®¾ç½®ï¼š

```yaml
prompts:
  - id: "string"              # æç¤ºè¯å”¯ä¸€æ ‡è¯†ç¬¦ (å¿…å¡«)
    version: "string"         # ç‰ˆæœ¬å· (å¿…å¡«)
    content: "string"         # æç¤ºè¯å†…å®¹ (content å’Œ file äºŒé€‰ä¸€)
    file: "path/to/file"      # æç¤ºè¯æ–‡ä»¶è·¯å¾„ (content å’Œ file äºŒé€‰ä¸€)
```

**ç¤ºä¾‹**ï¼š
```yaml
prompts:
  - id: "default_system"
    version: "v1.0"
    content: "ä½ æ˜¯ä¸€ä¸ªå‹å–„ã€æœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"
  
  - id: "casual_chat"
    version: "v1.1" 
    file: "prompts/casual_system.txt"
```

#### 2. `models` - æ¨¡å‹é…ç½®
å®šä¹‰è¦è¯„ä¼°çš„æ¨¡å‹å’Œå‚æ•°ï¼š

```yaml
models:
  - name: "string"            # æ¨¡å‹åç§°æ ‡è¯† (å¿…å¡«)
    host: "string"            # API åŸºç¡€ URL (å¯é€‰, é»˜è®¤: http://127.0.0.1:8005/v1)
    api_key: "string"         # API å¯†é’¥ (å¯é€‰, æ”¯æŒç¯å¢ƒå˜é‡ ${VAR_NAME})
    params:                   # æ¨¡å‹å‚æ•° (å¿…å¡«)
      model: "string"         # æ¨¡å‹æ ‡è¯†ç¬¦ (å¿…å¡«)
      temperature: float      # é‡‡æ ·æ¸©åº¦ (å¯é€‰, 0.0-2.0)
      max_tokens: int         # æœ€å¤§ç”Ÿæˆtokenæ•° (å¯é€‰)
      top_p: float           # æ ¸é‡‡æ ·å‚æ•° (å¯é€‰, 0.0-1.0)
      top_k: int             # Top-Ké‡‡æ · (å¯é€‰)
      frequency_penalty: float # é¢‘ç‡æƒ©ç½š (å¯é€‰, -2.0-2.0)
      presence_penalty: float  # å­˜åœ¨æƒ©ç½š (å¯é€‰, -2.0-2.0)
      stop: [string]          # åœæ­¢è¯åˆ—è¡¨ (å¯é€‰)
```

**æ”¯æŒçš„ API ç±»å‹**ï¼š
- **æœ¬åœ° WeClone**: `http://127.0.0.1:8005/v1`
- **OpenAI**: `https://api.openai.com/v1`
- **OpenRouter**: `https://openrouter.ai/api/v1`
- **é˜¿é‡Œé€šä¹‰**: `https://dashscope.aliyuncs.com/compatible-mode/v1`
- **æ™ºè°± GLM**: `https://open.bigmodel.cn/api/paas/v4`

**ç¤ºä¾‹**ï¼š
```yaml
models:
  # æœ¬åœ°å¾®è°ƒæ¨¡å‹
  - name: "weclone-local"
    host: "http://127.0.0.1:8005/v1"
    api_key: "sk-test"
    params:
      model: "gpt-3.5-turbo"
      temperature: 0.7
      max_tokens: 512
      top_p: 0.9
  
  # OpenRouter ç¬¬ä¸‰æ–¹æ¨¡å‹
  - name: "deepseek-v3"
    host: "https://openrouter.ai/api/v1"
    api_key: "${OPENROUTER_API_KEY}"
    params:
      model: "deepseek/deepseek-chat-v3-0324"
      temperature: 0.5
      max_tokens: 1024
```

#### 3. `cases` - æµ‹è¯•æ•°æ®é…ç½®
å®šä¹‰æµ‹è¯•æ•°æ®æ¥æºï¼š

```yaml
cases:
  - file: "path/to/data.json"   # JSON æ ¼å¼æ•°æ®æ–‡ä»¶
  - file: "path/to/data.jsonl"  # JSONL æ ¼å¼æ•°æ®æ–‡ä»¶
```

**æ”¯æŒçš„æ•°æ®æ ¼å¼**ï¼š

**JSON æ ¼å¼** (å…¼å®¹ç°æœ‰ test_data.json):
```json
{
  "questions": [
    ["é—®é¢˜1", "é—®é¢˜2"],
    ["å¦ä¸€ç»„é—®é¢˜"]
  ]
}
```

**JSONL æ ¼å¼** (æ¯è¡Œä¸€ä¸ªå¯¹è¯):
```jsonl
{"conversation": [{"role": "user", "content": "ä½ å¥½"}, {"role": "assistant", "content": ""}]}
{"conversation": [{"role": "user", "content": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}, {"role": "assistant", "content": ""}]}
```

#### 4. `metrics` - è¯„ä¼°æŒ‡æ ‡
æŒ‡å®šè¦ä½¿ç”¨çš„è¯„ä¼°åŸºå‡†ï¼š

```yaml
metrics:
  - "interaction_fluency"     # äº¤äº’æµç•…åº¦
  - "sentiment_satisfaction"  # æƒ…æ„Ÿæ»¡æ„åº¦
  - "task_success"           # ä»»åŠ¡æˆåŠŸç‡
  - "latency"                # å»¶è¿Ÿæ€§èƒ½
  - "cost"                   # æˆæœ¬åˆ†æ
  - "chathumanscore"         # äººç±»åŒ–è¯„åˆ† (éœ€é¢å¤–ä¾èµ–)
```

### é«˜çº§é…ç½®å‚æ•°

#### 5. `benchmark_configs` - åŸºå‡†è‡ªå®šä¹‰é…ç½®
ä¸ºæ¯ä¸ªåŸºå‡†æä¾›ä¸“é—¨çš„é…ç½®ï¼š

```yaml
benchmark_configs:
  # äº¤äº’æµç•…åº¦é…ç½®
  interaction_fluency:
    interrupt_threshold_ms: 300        # ä¸­æ–­é˜ˆå€¼ (æ¯«ç§’)
    timeout_threshold_ms: 25000       # è¶…æ—¶é˜ˆå€¼ (æ¯«ç§’)
  
  # æƒ…æ„Ÿæ»¡æ„åº¦é…ç½®  
  sentiment_satisfaction:
    positive_words: ["å¥½", "æ£’", "æ»¡æ„"]  # ç§¯æè¯æ±‡
    negative_words: ["å·®", "ç³Ÿç³•", "ä¸æ»¡"] # æ¶ˆæè¯æ±‡
    base_rating: 3.5                    # åŸºç¡€è¯„åˆ†
    rating_sensitivity: 0.8             # è¯„åˆ†æ•æ„Ÿåº¦
  
  # ä»»åŠ¡æˆåŠŸç‡é…ç½®
  task_success:
    bleu_weight: 0.4                   # BLEU æƒé‡
    precision_weight: 0.3              # ç²¾ç¡®ç‡æƒé‡
    recall_weight: 0.3                 # å¬å›ç‡æƒé‡
  
  # å»¶è¿Ÿæ€§èƒ½é…ç½®
  latency:
    first_token_excellent_ms: 500      # ä¼˜ç§€é¦–tokenæ—¶é—´
    first_token_good_ms: 1000         # è‰¯å¥½é¦–tokenæ—¶é—´
    full_response_excellent_ms: 2000   # ä¼˜ç§€å®Œæ•´å“åº”æ—¶é—´
    full_response_good_ms: 5000       # è‰¯å¥½å®Œæ•´å“åº”æ—¶é—´
  
  # æˆæœ¬åˆ†æé…ç½®
  cost:
    model_pricing:                     # è‡ªå®šä¹‰æ¨¡å‹å®šä»·
      "gpt-4":
        prompt: 0.03                   # è¾“å…¥tokenä»·æ ¼ (USD/1K)
        completion: 0.06               # è¾“å‡ºtokenä»·æ ¼ (USD/1K)
      "deepseek/deepseek-chat-v3-0324":
        prompt: 0.0014
        completion: 0.0028
    excellent_cost_per_token: 0.000005 # ä¼˜ç§€æˆæœ¬é˜ˆå€¼
    good_cost_per_token: 0.00005      # è‰¯å¥½æˆæœ¬é˜ˆå€¼
    
  # ChatHumanScore é…ç½® (éœ€å®‰è£…é¢å¤–ä¾èµ–)
  chathumanscore:
    enable_grammar_check: true         # å¯ç”¨è¯­æ³•æ£€æŸ¥
    enable_semantic_analysis: true     # å¯ç”¨è¯­ä¹‰åˆ†æ
    enable_gpt_judge: false           # å¯ç”¨GPTè¯„åˆ¤
    max_grammar_error_rate: 0.05      # æœ€å¤§è¯­æ³•é”™è¯¯ç‡
    max_repeat_ratio: 0.30            # æœ€å¤§é‡å¤ç‡
    human_review_threshold: 5.0       # äººå·¥å®¡æ ¸é˜ˆå€¼
    score_weights:                    # è¯„åˆ†æƒé‡
      naturalness: 0.25              # è‡ªç„¶åº¦
      affective_alignment: 0.20       # æƒ…æ„Ÿå¯¹é½
      diversity: 0.15                # å¤šæ ·æ€§
      context_cohesion: 0.20         # ä¸Šä¸‹æ–‡ç²˜æ€§
      human_signal: 0.20             # äººç±»ä¿¡å·
```

#### 6. `debug` - è°ƒè¯•æ¨¡å¼é…ç½®
å¿«é€Ÿè¿­ä»£å¼€å‘çš„è°ƒè¯•é€‰é¡¹ï¼š

```yaml
debug:
  max_cases: 3                      # é™åˆ¶æµ‹è¯•æ¡ˆä¾‹æ•°é‡
  verbose: true                     # è¯¦ç»†æ—¥å¿—è¾“å‡º
  save_intermediate: true           # ä¿å­˜ä¸­é—´ç»“æœ
```

#### 7. æ‰§è¡Œæ§åˆ¶å‚æ•°

```yaml
# å¹¶å‘æ§åˆ¶
parallel: 2                         # å¹¶å‘workersæ•°é‡ (é»˜è®¤: 1)

# æˆæœ¬æ§åˆ¶
max_usd: 10.0                      # æœ€å¤§æˆæœ¬é™åˆ¶ USD (é»˜è®¤: æ— é™åˆ¶)

# è¶…æ—¶æ§åˆ¶
timeout_seconds: 60                # å•ä¸ªè¯·æ±‚è¶…æ—¶æ—¶é—´ (é»˜è®¤: 30ç§’)

# è¾“å‡ºæ§åˆ¶
output_formats:                    # è¾“å‡ºæ ¼å¼ (é»˜è®¤: ["csv"])
  - "csv"                         # CSV æ ¼å¼
  - "json"                        # JSON æ ¼å¼
  - "summary_report"              # æ‘˜è¦æŠ¥å‘Š
```

### ç¯å¢ƒå˜é‡æ”¯æŒ

é…ç½®æ–‡ä»¶æ”¯æŒç¯å¢ƒå˜é‡æ›¿æ¢ï¼Œä½¿ç”¨ `${VAR_NAME}` è¯­æ³•ï¼š

```yaml
models:
  - name: "openai-gpt4"
    api_key: "${OPENAI_API_KEY}"     # ä»ç¯å¢ƒå˜é‡è¯»å–
    host: "${OPENAI_BASE_URL}"       # å¯é€‰çš„è‡ªå®šä¹‰ç«¯ç‚¹
```

**å¸¸ç”¨ç¯å¢ƒå˜é‡**ï¼š
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="your_openai_key"
export OPENROUTER_API_KEY="your_openrouter_key"  
export DASHSCOPE_API_KEY="your_qwen_key"
export GLM_API_KEY="your_glm_key"
```

### å®Œæ•´é…ç½®ç¤ºä¾‹

```yaml
batch_name: "comprehensive_model_evaluation"

prompts:
  - id: "system_default"
    version: "v1.0"
    content: "ä½ æ˜¯ä¸€ä¸ªå‹å–„ã€ä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚"
  
  - id: "casual_chat"
    version: "v1.1"
    content: "ä½ æ˜¯ç”¨æˆ·çš„æœ‹å‹ï¼Œç”¨è½»æ¾çš„è¯­æ°”èŠå¤©ã€‚"

models:
  - name: "weclone-local"
    host: "http://127.0.0.1:8005/v1"
    api_key: "sk-test"
    params:
      model: "gpt-3.5-turbo"
      temperature: 0.7
      max_tokens: 512
  
  - name: "deepseek-v3"
    host: "https://openrouter.ai/api/v1"
    api_key: "${OPENROUTER_API_KEY}"
    params:
      model: "deepseek/deepseek-chat-v3-0324"
      temperature: 0.5
      max_tokens: 1024
      top_p: 0.9

cases:
  - file: "dataset/test_data.json"
  - file: "dataset/additional_cases.jsonl"

metrics:
  - "interaction_fluency"
  - "sentiment_satisfaction"
  - "latency"
  - "cost"

benchmark_configs:
  cost:
    model_pricing:
      "deepseek/deepseek-chat-v3-0324":
        prompt: 0.0014
        completion: 0.0028
    excellent_cost_per_token: 0.000005

debug:
  max_cases: 5

parallel: 2
max_usd: 5.0
timeout_seconds: 60
output_formats: ["csv", "json"]
```

### è¾“å‡ºç»“æœ

è¯„ä¼°ç»“æœä¿å­˜åœ¨ `eval_runs/<æ—¶é—´æˆ³>/` ç›®å½•ï¼š

```
eval_runs/20241201T143022Z_a1b2c3d4/
â”œâ”€â”€ run_meta.json              # è¿è¡Œå…ƒæ•°æ®å’Œé…ç½®
â”œâ”€â”€ dataset.csv                # å®Œæ•´å¯¹è¯æ•°æ®é›†
â”œâ”€â”€ benchmark_results.csv      # æ‰€æœ‰åŸºå‡†æŒ‡æ ‡
â””â”€â”€ latency_cost.csv          # å»¶è¿Ÿå’Œæˆæœ¬æ±‡æ€»
```

#### CSV è¾“å‡ºæ ¼å¼

**benchmark_results.csv**:
```csv
run_id,conv_id,model,prompt,benchmark,metric,value
20241201T143022Z_a1b2c3d4,0,deepseek:chat-v3,default_system,latency,full_response_ms,1234.56
20241201T143022Z_a1b2c3d4,0,deepseek:chat-v3,default_system,cost,usd_cost,0.0028
```

**latency_cost.csv**:
```csv
run_id,conv_id,model,n_tokens_prompt,n_tokens_completion,latency_ms,cost_usd
20241201T143022Z_a1b2c3d4,0,deepseek:chat-v3,45,128,1234.56,0.0028
```

### è‡ªå®šä¹‰åŸºå‡†

åˆ›å»ºè‡ªå®šä¹‰è¯„ä¼°åŸºå‡†ï¼š

```python
from weclone.eval.benchmark.base import BaseBenchmark, BenchmarkResult
from weclone.eval.framework import JobContext

class CustomBenchmark(BaseBenchmark):
    @property 
    def name(self) -> str:
        return "custom_benchmark"
    
    def required_artifacts(self) -> List[str]:
        return ["conversation_text"]
        
    def compute(self, job_ctx: JobContext) -> BenchmarkResult:
        # è‡ªå®šä¹‰è¯„ä¼°é€»è¾‘
        metrics = {"custom_metric": 0.85}
        return BenchmarkResult(
            benchmark_name=self.name,
            metrics=metrics
        )
```

åœ¨ `weclone/eval/benchmark/__init__.py` ä¸­æ³¨å†Œï¼š
```python
AVAILABLE_BENCHMARKS = {
    # ... ç°æœ‰åŸºå‡†
    'custom_benchmark': CustomBenchmark
}
```

### é›†æˆå·¥ä½œæµ

è¯„ä¼°æ¡†æ¶ä¸ WeClone å…¶ä»–ç»„ä»¶æ— ç¼é›†æˆï¼š

1. **è®­ç»ƒåè¯„ä¼°**: å¾®è°ƒå®Œæˆåè‡ªåŠ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½
2. **A/B æµ‹è¯•**: æ¯”è¾ƒä¸åŒæ¨¡å‹ã€å‚æ•°é…ç½®çš„æ•ˆæœ
3. **æŒç»­ç›‘æ§**: å®šæœŸè¯„ä¼°ç”Ÿäº§ç¯å¢ƒæ¨¡å‹è¡¨ç°
4. **æ¨¡å‹é€‰æ‹©**: åŸºäºè¯„ä¼°ç»“æœé€‰æ‹©æœ€ä½³æ¨¡å‹é…ç½®

## ğŸ”§ å…¸å‹å·¥ä½œæµç¨‹

### å®Œæ•´çš„æ•°å­—åˆ†èº«åˆ›å»ºæµç¨‹:

1. **å‡†å¤‡æ•°æ®**
   ```bash
   # å°†èŠå¤©è®°å½•CSVæ–‡ä»¶æ”¾å…¥ ./dataset/csv/ ç›®å½•
   weclone-cli make-dataset
   ```

2. **è®­ç»ƒæ¨¡å‹**
   ```bash
   weclone-cli train-sft
   ```

3. **æµ‹è¯•æ•ˆæœ**
   ```bash
   # Webç•Œé¢æµ‹è¯•
   weclone-cli webchat-demo
   
   # æˆ–å¯åŠ¨APIæœåŠ¡è¿›è¡Œæµ‹è¯•
   weclone-cli server
   ```

4. **æ€§èƒ½è¯„ä¼°**
   ```bash
   # åŸºç¡€æµ‹è¯•
   weclone-cli test-model
   
   # ç»¼åˆè¯„ä¼°
   weclone-cli eval-framework --config weclone/eval/config/simple_test.yaml
   ```

5. **å¯¼å‡ºåˆ°Ollama (å¯é€‰)**
   ```bash
   # æ–¹æ³•1: ä½¿ç”¨ä¾¿æ·å®‰è£…è„šæœ¬ (æ¨è) - ä¸‹è½½é¢„ç¼–è¯‘ç‰ˆæœ¬
   ./scripts/install_llama_cpp.sh
   
   # æ–¹æ³•2: æ‰‹åŠ¨ä¸‹è½½é¢„ç¼–è¯‘ç‰ˆæœ¬
   # è®¿é—® https://github.com/ggerganov/llama.cpp/releases
   # ä¸‹è½½é€‚åˆæ‚¨ç³»ç»Ÿçš„é¢„ç¼–è¯‘ç‰ˆæœ¬ï¼Œè§£å‹å¹¶æ·»åŠ åˆ° PATH
   
   # æ–¹æ³•3: ä»æºç ç¼–è¯‘ï¼ˆä»…åœ¨é¢„ç¼–è¯‘ç‰ˆæœ¬ä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
   git clone https://github.com/ggerganov/llama.cpp.git
   cd llama.cpp && make
   sudo ln -s $(pwd)/convert-hf-to-gguf.py /usr/local/bin/
   sudo ln -s $(pwd)/quantize /usr/local/bin/
   
   # å¯¼å‡ºæ¨¡å‹ä¸ºGGUFæ ¼å¼
   weclone-cli export-to-gguf
   
   # å°† ollama_export æ–‡ä»¶å¤¹å¤åˆ¶åˆ°Windowsç³»ç»Ÿ
   # åœ¨Windowsä¸ŠåŒå‡»è¿è¡Œ deploy_to_ollama.bat
   ```

6. **éƒ¨ç½²åº”ç”¨**
   ```bash
   # ä¿æŒAPIæœåŠ¡è¿è¡Œï¼Œä¾›èŠå¤©æœºå™¨äººè°ƒç”¨
   weclone-cli server
   ```

## âš™ï¸ é…ç½®æ–‡ä»¶

- **ä¸»é…ç½®**: `settings.jsonc` - åŒ…å«æ‰€æœ‰æ¨¡å—çš„é…ç½®å‚æ•°
- **è¯„ä¼°é…ç½®**: `weclone/eval/config/*.yaml` - è¯„ä¼°æ¡†æ¶ä¸“ç”¨é…ç½®

## ğŸ’¡ ä½¿ç”¨æç¤º

- æ‰€æœ‰å‘½ä»¤éœ€è¦å¯åŠ¨è™šæ‹Ÿç¯å¢ƒï¼Œç„¶ååœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ
- ç¡®ä¿ `settings.jsonc` é…ç½®æ–‡ä»¶å­˜åœ¨ä¸”é…ç½®æ­£ç¡®
- è¯„ä¼°æ¡†æ¶éœ€è¦å…ˆå¯åŠ¨ API æœåŠ¡
- ä½¿ç”¨ `--help` æŸ¥çœ‹å‘½ä»¤è¯¦ç»†å¸®åŠ©: `uv run python -m weclone.cli [COMMAND] --help`

---


<p align="center">
  <a href="https://blog.051088.xyz/2025/05/14/WeClone-%E7%94%A8%E5%BE%AE%E4%BF%A1%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84AI%E6%95%B0%E5%AD%97%E5%88%86%E8%BA%AB/" target="_blank">
    Windowséƒ¨ç½²æŒ‡å—
  </a>
  <a>|</a>
  <a href="https://blog.051088.xyz/posts/weclone-linux-tutorial/" target="_blank">
    Linuxéƒ¨ç½²æŒ‡å—ã€ä¿å§†çº§ã€‘
  </a>
</p>

> [!IMPORTANT]
> <h3> WhatsApp and Telegram chat logs integration for digital avatar creation is coming ! </h3>

## âœ¨æ ¸å¿ƒåŠŸèƒ½
- ğŸ’« æ¶µç›–æ‰“é€ æ•°å­—åˆ†èº«çš„å…¨é“¾è·¯æ–¹æ¡ˆï¼ŒåŒ…æ‹¬èŠå¤©æ•°æ®å¯¼å‡ºã€é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€éƒ¨ç½²
- ğŸ’¬ ä½¿ç”¨å¾®ä¿¡èŠå¤©è®°å½•å¾®è°ƒLLMï¼Œè®©å¤§æ¨¡å‹æœ‰"é‚£å‘³å„¿"
- ğŸ”— ç»‘å®šåˆ°å¾®ä¿¡ã€QQã€Telegramã€ä¼å¾®ã€é£ä¹¦æœºå™¨äººï¼Œå®ç°è‡ªå·±çš„æ•°å­—åˆ†èº«
- ğŸ›¡ï¸ éšç§ä¿¡æ¯è¿‡æ»¤ï¼Œæœ¬åœ°åŒ–å¾®è°ƒéƒ¨ç½²ï¼Œæ•°æ®å®‰å…¨å¯æ§

## ğŸ“‹ç‰¹æ€§ä¸è¯´æ˜

> [!IMPORTANT]
> - WeCloneä»åœ¨å¿«é€Ÿè¿­ä»£æœŸï¼Œå½“å‰æ•ˆæœä¸ä»£è¡¨æœ€ç»ˆæ•ˆæœã€‚  
> - å¾®è°ƒLLMæ•ˆæœå¾ˆå¤§ç¨‹åº¦å–å†³äºæ¨¡å‹å¤§å°ã€èŠå¤©æ•°æ®çš„æ•°é‡å’Œè´¨é‡ï¼Œç†è®ºä¸Šæ¨¡å‹è¶Šå¤§ï¼Œæ•°æ®è¶Šå¤šï¼Œæ•ˆæœè¶Šå¥½ã€‚   
> - Windowsç¯å¢ƒæœªè¿›è¡Œä¸¥æ ¼æµ‹è¯•ï¼Œå¯ä»¥ä½¿ç”¨WSLä½œä¸ºè¿è¡Œç¯å¢ƒã€‚è¯¦ç»†æ•™ç¨‹å¯ç‚¹å‡»[Windowséƒ¨ç½²æŒ‡å—](https://blog.051088.xyz/2025/05/14/WeClone-%E7%94%A8%E5%BE%AE%E4%BF%A1%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84AI%E6%95%B0%E5%AD%97%E5%88%86%E8%BA%AB/)æŸ¥çœ‹ã€‚

### ç¡¬ä»¶è¦æ±‚

é¡¹ç›®é»˜è®¤ä½¿ç”¨Qwen2.5-7B-Instructæ¨¡å‹ï¼ŒLoRAæ–¹æ³•å¯¹sfté˜¶æ®µå¾®è°ƒï¼Œå¤§çº¦éœ€è¦16GBæ˜¾å­˜ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨[LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md#%E6%A8%A1%E5%9E%8B)æ”¯æŒçš„å…¶ä»–æ¨¡å‹å’Œæ–¹æ³•ã€‚

éœ€è¦æ˜¾å­˜çš„ä¼°ç®—å€¼ï¼š
| æ–¹æ³•                             | ç²¾åº¦ |   7B  |  14B  |  30B  |   70B  |   `x`B  |
| ------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |
| Full (`bf16` or `fp16`)         |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |
| Full (`pure_bf16`)              |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |
| Freeze/LoRA/GaLore/APOLLO/BAdam |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |
| QLoRA                           |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |
| QLoRA                           |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |
| QLoRA                           |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |


## ç¯å¢ƒæ­å»º
1.cudaå®‰è£…(å·²å®‰è£…å¯è·³è¿‡ï¼Œ**è¦æ±‚ç‰ˆæœ¬12.4åŠä»¥ä¸Š**)ï¼š[LLaMA Factory](https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/installation.html#cuda) 

2.å»ºè®®ä½¿ç”¨ [uv](https://docs.astral.sh/uv/)å®‰è£…ä¾èµ–ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å¿«é€Ÿçš„ Python ç¯å¢ƒç®¡ç†å™¨ã€‚å®‰è£…uvåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åˆ›å»ºä¸€ä¸ªæ–°çš„Pythonç¯å¢ƒå¹¶å®‰è£…ä¾èµ–é¡¹ï¼Œæ³¨æ„è¿™ä¸åŒ…å«éŸ³é¢‘å…‹éš†åŠŸèƒ½çš„ä¾èµ–ï¼š
```bash
git clone https://github.com/xming521/WeClone.git
cd WeClone
uv venv .venv --python=3.10
source .venv/bin/activate # windowsä¸‹æ‰§è¡Œ .venv\Scripts\activate
uv pip install --group main -e . 
```
> [!TIP]
> å¦‚æœè¦ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œéœ€è¦æ‰‹åŠ¨å®‰è£…æœ€æ–°ç‰ˆLLaMA Factoryï¼š`uv pip install --upgrade git+https://github.com/hiyouga/LLaMA-Factory.git`,åŒæ—¶å…¶ä»–ä¾èµ–ç‰ˆæœ¬ä¹Ÿå¯èƒ½éœ€è¦ä¿®æ”¹ï¼Œä¾‹å¦‚vllm pytorch transforms

3.å°†é…ç½®æ–‡ä»¶æ¨¡æ¿å¤åˆ¶ä¸€ä»½å¹¶é‡å‘½åä¸º`settings.jsonc`ï¼Œåç»­é…ç½®ä¿®æ”¹åœ¨æ­¤æ–‡ä»¶è¿›è¡Œï¼š
```bash
cp settings.template.jsonc settings.jsonc
```
> [!NOTE]
> è®­ç»ƒä»¥åŠæ¨ç†ç›¸å…³é…ç½®ç»Ÿä¸€åœ¨æ–‡ä»¶`settings.jsonc`

4.ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æµ‹è¯•CUDAç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®å¹¶å¯è¢«PyTorchè¯†åˆ«ï¼ŒMacä¸éœ€è¦ï¼š
```bash
python -c "import torch; print('CUDAæ˜¯å¦å¯ç”¨:', torch.cuda.is_available());"
```

5.ï¼ˆå¯é€‰ï¼‰å®‰è£…FlashAttentionï¼ŒåŠ é€Ÿè®­ç»ƒå’Œæ¨ç†ï¼š`uv pip install flash-attn --no-build-isolation`

## æ¨¡å‹ä¸‹è½½
```bash
git lfs install
git clone https://www.modelscope.cn/Qwen/Qwen2.5-7B-Instruct.git
```
ä¸‹è½½æœ‰é—®é¢˜ä½¿ç”¨å…¶ä»–æ–¹å¼ä¸‹è½½ï¼š[æ¨¡å‹çš„ä¸‹è½½](https://www.modelscope.cn/docs/models/download)


## æ•°æ®å‡†å¤‡

è¯·ä½¿ç”¨[PyWxDump](https://github.com/xaoyaoo/PyWxDump)æå–å¾®ä¿¡èŠå¤©è®°å½•ï¼ˆä¸æ”¯æŒ4.0ç‰ˆæœ¬å¾®ä¿¡ï¼‰ã€‚å¯ä»¥å…ˆå°†æ‰‹æœºçš„èŠå¤©è®°å½•è¿ç§»ï¼ˆå¤‡ä»½ï¼‰åˆ°ç”µè„‘ï¼Œæ•°æ®é‡æ›´å¤šä¸€äº›ã€‚ä¸‹è½½è½¯ä»¶å¹¶è§£å¯†æ•°æ®åº“åï¼Œç‚¹å‡»èŠå¤©å¤‡ä»½ï¼Œå¯¼å‡ºç±»å‹ä¸ºCSVï¼Œå¯ä»¥å¯¼å‡ºå¤šä¸ªè”ç³»äººï¼ˆä¸å»ºè®®ä½¿ç”¨ç¾¤èŠè®°å½•ï¼‰ï¼Œç„¶åå°†å¯¼å‡ºçš„ä½äº`wxdump_tmp/export` çš„ `csv` æ–‡ä»¶å¤¹æ”¾åœ¨`./dataset`ç›®å½•å³å¯ï¼Œä¹Ÿå°±æ˜¯ä¸åŒäººèŠå¤©è®°å½•çš„æ–‡ä»¶å¤¹ä¸€èµ·æ”¾åœ¨ `./dataset/csv`ã€‚   

## æ•°æ®é¢„å¤„ç†

- é¡¹ç›®é»˜è®¤å»é™¤äº†æ•°æ®ä¸­çš„æ‰‹æœºå·ã€èº«ä»½è¯å·ã€é‚®ç®±ã€ç½‘å€ã€‚è¿˜åœ¨`settings.jsonc`ä¸­æä¾›äº†ä¸€ä¸ªç¦ç”¨è¯è¯åº“`blocked_words`ï¼Œå¯ä»¥è‡ªè¡Œæ·»åŠ éœ€è¦è¿‡æ»¤çš„è¯å¥ï¼ˆä¼šé»˜è®¤å»æ‰åŒ…æ‹¬ç¦ç”¨è¯çš„æ•´å¥ï¼‰ã€‚
> [!IMPORTANT]
> ğŸš¨ è¯·ä¸€å®šæ³¨æ„ä¿æŠ¤ä¸ªäººéšç§ï¼Œä¸è¦æ³„éœ²ä¸ªäººä¿¡æ¯ï¼

- æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼Œå¯ä»¥æ ¹æ®è‡ªå·±çš„èŠå¤©é£æ ¼ä¿®æ”¹settings.jsoncçš„`make_dataset_args`ã€‚
```bash
weclone-cli make-dataset
```
- ç›®å‰ä»…æ”¯æŒæ—¶é—´çª—å£ç­–ç•¥ï¼Œæ ¹æ®`single_combine_time_window`å°†å•äººè¿ç»­æ¶ˆæ¯é€šè¿‡é€—å·è¿æ¥åˆå¹¶ä¸ºä¸€å¥ï¼Œæ ¹æ®`qa_match_time_window`åŒ¹é…é—®ç­”å¯¹ã€‚
- å¯ä»¥å¯ç”¨`clean_dataset`ä¸­çš„`enable_clean`é€‰é¡¹ï¼Œå¯¹æ•°æ®è¿›è¡Œæ¸…æ´—ï¼Œä»¥è¾¾åˆ°æ›´å¥½æ•ˆæœã€‚* å½“å‰ç³»ç»Ÿæ”¯æŒä½¿ç”¨ `llm judge` å¯¹èŠå¤©è®°å½•è¿›è¡Œæ‰“åˆ†ï¼Œæä¾› **vllm ç¦»çº¿æ¨ç†** å’Œ **API åœ¨çº¿æ¨ç†** ä¸¤ç§æ–¹å¼ã€‚å¯é€šè¿‡å°† `settings.jsonc` æ–‡ä»¶ä¸­çš„ `"online_llm_clear": false` ä¿®æ”¹ä¸º `true` æ¥å¯ç”¨ API åœ¨çº¿æ¨ç†æ¨¡å¼ï¼Œå¹¶é…ç½®ç›¸åº”çš„ `base_url`ã€`llm_api_key`ã€`model_name` ç­‰å‚æ•°ã€‚æ‰€æœ‰å…¼å®¹ OpenAI æ¥å£çš„æ¨¡å‹å‡å¯æ¥å…¥ã€‚
- åœ¨è·å¾— `llm æ‰“åˆ†åˆ†æ•°åˆ†å¸ƒæƒ…å†µ` åï¼Œå¯é€šè¿‡è®¾ç½® `accept_score` å‚æ•°ç­›é€‰å¯æ¥å—çš„åˆ†æ•°åŒºé—´ï¼ŒåŒæ—¶å¯é€‚å½“é™ä½ `train_sft_args` ä¸­çš„ `lora_dropout` å‚æ•°ï¼Œä»¥æå‡æ¨¡å‹çš„æ‹Ÿåˆæ•ˆæœã€‚

## é…ç½®å‚æ•°å¹¶å¾®è°ƒæ¨¡å‹

- (å¯é€‰)ä¿®æ”¹ `settings.jsonc` çš„ `model_name_or_path` å’Œ `template` é€‰æ‹©æœ¬åœ°ä¸‹è½½å¥½çš„å…¶ä»–æ¨¡å‹ã€‚  
- ä¿®æ”¹`per_device_train_batch_size`ä»¥åŠ`gradient_accumulation_steps`æ¥è°ƒæ•´æ˜¾å­˜å ç”¨ã€‚  
- å¯ä»¥æ ¹æ®è‡ªå·±æ•°æ®é›†çš„æ•°é‡å’Œè´¨é‡ä¿®æ”¹`train_sft_args`çš„`num_train_epochs`ã€`lora_rank`ã€`lora_dropout`ç­‰å‚æ•°ã€‚

### å•å¡è®­ç»ƒ
```bash
weclone-cli train-sft
```
å¤šå¡ç¯å¢ƒå•å¡è®­ç»ƒï¼Œéœ€è¦å…ˆæ‰§è¡Œ `export CUDA_VISIBLE_DEVICES=0`

### å¤šå¡è®­ç»ƒ
å–æ¶ˆ`settings.jsonc`ä¸­`deepspeed`è¡Œä»£ç æ³¨é‡Šï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¤šå¡è®­ç»ƒï¼š
```bash
uv pip install deepspeed
deepspeed --num_gpus=ä½¿ç”¨æ˜¾å¡æ•°é‡ weclone/train/train_sft.py
```

### ä½¿ç”¨æµè§ˆå™¨demoç®€å•æ¨ç†
å¯ä»¥åœ¨è¿™ä¸€æ­¥æµ‹è¯•å‡ºåˆé€‚çš„temperatureã€top_på€¼ï¼Œä¿®æ”¹settings.jsoncçš„`infer_args`åï¼Œä¾›åç»­æ¨ç†æ—¶ä½¿ç”¨ã€‚
```bash
weclone-cli webchat-demo
```

### ä½¿ç”¨æ¥å£è¿›è¡Œæ¨ç†

```bash
weclone-cli server
```

### ä½¿ç”¨å¸¸è§èŠå¤©é—®é¢˜æµ‹è¯•
ä¸åŒ…å«è¯¢é—®ä¸ªäººä¿¡æ¯çš„é—®é¢˜ï¼Œä»…æœ‰æ—¥å¸¸èŠå¤©ã€‚æµ‹è¯•ç»“æœåœ¨test_result-my.txtã€‚
```bash
weclone-cli server
weclone-cli test-model
```

## ğŸ–¼ï¸ å¾®è°ƒæ•ˆæœ
ä½¿ç”¨Qwen2.5-14B-Instructæ¨¡å‹ï¼Œå¤§æ¦‚3ä¸‡æ¡å¤„ç†åçš„æœ‰æ•ˆæ•°æ®ï¼Œlossé™åˆ°äº†3.5å·¦å³çš„æ•ˆæœã€‚
<details>
<summary>æˆªå›¾</summary>
<div style="display: flex; flex-wrap: wrap; gap: 10px;">
  <img src="https://github.com/user-attachments/assets/0775ec52-452b-485f-9785-c6eb7b277132" alt="alt text" style="width: 48%; min-width: 150px;">
  <img src="https://github.com/user-attachments/assets/8c7628b5-da70-4c37-9e51-fdfb0eadd2df" alt="alt text" style="width: 48%; min-width: 150px;">
  <img src="https://github.com/user-attachments/assets/523aa742-2aa3-40e9-bd67-b98b336e83a8" alt="alt text" style="width: 48%; min-width: 150px;">
  <img src="https://github.com/user-attachments/assets/dabf0603-dcc4-4a47-b5c3-2bbc036820d9" alt="alt text" style="width: 48%; min-width: 150px;">
</div>
</details>


## ğŸ¤– éƒ¨ç½²åˆ°èŠå¤©æœºå™¨äºº

### AstrBot

[AstrBot](https://github.com/AstrBotDevs/AstrBot) æ˜¯æ˜“ä¸Šæ‰‹çš„å¤šå¹³å° LLM èŠå¤©æœºå™¨äººåŠå¼€å‘æ¡†æ¶ âœ¨ å¹³å°æ”¯æŒ QQã€QQé¢‘é“ã€Telegramã€å¾®ä¿¡ã€ä¼å¾®ã€é£ä¹¦ã€‚      

ä½¿ç”¨æ­¥éª¤ï¼š
1. éƒ¨ç½² AstrBot
2. åœ¨ AstrBot ä¸­éƒ¨ç½²æ¶ˆæ¯å¹³å°
3. æ‰§è¡Œ `weclone-cli server` å¯åŠ¨apiæœåŠ¡
4. åœ¨ AstrBot ä¸­æ–°å¢æœåŠ¡æä¾›å•†ï¼Œç±»å‹é€‰æ‹©OpenAIï¼ŒAPI Base URL æ ¹æ®AstrBotéƒ¨ç½²æ–¹å¼å¡«å†™ï¼ˆä¾‹å¦‚dockeréƒ¨ç½²å¯èƒ½ä¸ºhttp://172.17.0.1:8005/v1ï¼‰ ï¼Œæ¨¡å‹å¡«å†™gpt-3.5-turbo,API Keyéšæ„å¡«å†™ä¸€ä¸ª
5. å¾®è°ƒåä¸æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œè¯·å…ˆå…³æ‰é»˜è®¤çš„å·¥å…·ï¼Œæ¶ˆæ¯å¹³å°å‘é€æŒ‡ä»¤ï¼š `/tool off all`ï¼Œå¦åˆ™ä¼šæ²¡æœ‰å¾®è°ƒåçš„æ•ˆæœã€‚ 
6. æ ¹æ®å¾®è°ƒæ—¶ä½¿ç”¨çš„default_systemï¼Œåœ¨ AstrBot ä¸­è®¾ç½®ç³»ç»Ÿæç¤ºè¯ã€‚
![5](https://github.com/user-attachments/assets/19de7072-076a-4cdf-8ae6-46b9b89f536a)
> [!IMPORTANT]
> æ£€æŸ¥api_serviceçš„æ—¥å¿—ï¼Œå°½é‡ä¿è¯å¤§æ¨¡å‹æœåŠ¡è¯·æ±‚çš„å‚æ•°å’Œå¾®è°ƒæ—¶ä¸€è‡´ï¼Œtoolæ’ä»¶èƒ½åŠ›éƒ½å…³æ‰ã€‚
7. è°ƒæ•´é‡‡æ ·å‚æ•°ï¼Œä¾‹å¦‚temperatureã€top_pã€top_kç­‰
[é…ç½®è‡ªå®šä¹‰çš„æ¨¡å‹å‚æ•°](https://astrbot.app/config/model-config.html#%E9%85%8D%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0)

### LangBot

[LangBot](https://github.com/RockChinQ/LangBot) æ˜¯ä¸€ä¸ªå¼€æºçš„æ¥å…¥å…¨çƒå¤šç§å³æ—¶é€šä¿¡å¹³å°çš„ LLM æœºå™¨äººå¹³å°ï¼Œé€‚åˆå„ç§åœºæ™¯ä½¿ç”¨ã€‚

1. [éƒ¨ç½² LangBot](https://github.com/RockChinQ/LangBot#-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8)
2. åœ¨ LangBot ä¸­æ·»åŠ ä¸€ä¸ªæœºå™¨äºº
4. åœ¨æ¨¡å‹é¡µæ·»åŠ æ–°æ¨¡å‹ï¼Œåç§°`gpt-3.5-turbo`ï¼Œä¾›åº”å•†é€‰æ‹© OpenAIï¼Œå¡«å†™ è¯·æ±‚ URL ä¸º WeClone çš„åœ°å€ï¼Œè¯¦ç»†è¿æ¥æ–¹å¼å¯ä»¥å‚è€ƒ[æ–‡æ¡£](https://docs.langbot.app/zh/workshop/network-details.html)ï¼ŒAPI Key ä»»æ„å¡«å†™ã€‚

<img width="400px" alt="image" src="https://github.com/user-attachments/assets/fc167dea-7c93-4d94-9c5f-db709d0320ba" />

6. åœ¨æµæ°´çº¿é…ç½®ä¸­é€‰æ‹©åˆšæ‰æ·»åŠ çš„æ¨¡å‹ï¼Œæˆ–ä¿®æ”¹æç¤ºè¯é…ç½®

<img width="400px" alt="image" src="https://github.com/user-attachments/assets/dbb0fd0a-f760-42db-acd0-bb99c859b52e" />

## ğŸ“Œ è·¯çº¿å›¾
- [ ] æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ï¼šåŒ…æ‹¬ä¸Šä¸‹æ–‡å¯¹è¯ã€èŠå¤©å¯¹è±¡ä¿¡æ¯ã€æ—¶é—´ç­‰ + æ€è€ƒ
- [ ] Memory æ”¯æŒ
- [ ] æ”¯æŒå¤šæ¨¡æ€
- [ ] æ•°æ®å¢å¼º
- [ ] æ”¯æŒGUI

## é—®é¢˜è§£å†³
- å¾®è°ƒé—®é¢˜ï¼š[LLaMA-Factory| FAQs | å¸¸è§é—®é¢˜](https://github.com/hiyouga/LLaMA-Factory/issues/4614) æˆ–è€…æ›´æ–¹ä¾¿çš„ [![æ›´æ–¹ä¾¿çš„Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/hiyouga/LLaMA-Factory)

## â¤ï¸ è´¡çŒ®ä»£ç 

æ¬¢è¿ä»»ä½• Issues/Pull Requestsï¼

ä½ å¯ä»¥é€šè¿‡æŸ¥çœ‹Issuesæˆ–å¸®åŠ©å®¡æ ¸ PRï¼ˆæ‹‰å–è¯·æ±‚ï¼‰æ¥è´¡çŒ®ã€‚å¯¹äºæ–°åŠŸèƒ½çš„æ·»åŠ ï¼Œè¯·å…ˆé€šè¿‡ Issue è®¨è®ºã€‚   
è¿è¡Œ`uv pip install --group dev -e .`å®‰è£…å¼€å‘ä¾èµ–ã€‚   
é¡¹ç›®ä½¿ç”¨`pytest`æµ‹è¯•(æµ‹è¯•è„šæœ¬å¾…å®Œå–„)ï¼Œ`pyright`æ£€æŸ¥ç±»å‹ï¼Œ`ruff`æ£€æŸ¥ä»£ç æ ¼å¼ã€‚


## âš ï¸ å…è´£å£°æ˜
> [!CAUTION]
> è¯·å‹¿ç”¨äºéæ³•ç”¨é€”ï¼Œå¦åˆ™åæœè‡ªè´Ÿã€‚
<details>
<summary>1. ä½¿ç”¨ç›®çš„</summary>

* æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ äº¤æµä½¿ç”¨ï¼Œ**è¯·å‹¿ç”¨äºéæ³•ç”¨é€”**ï¼Œ**è¯·å‹¿ç”¨äºéæ³•ç”¨é€”**ï¼Œ**è¯·å‹¿ç”¨äºéæ³•ç”¨é€”**ï¼Œå¦åˆ™åæœè‡ªè´Ÿã€‚
* ç”¨æˆ·ç†è§£å¹¶åŒæ„ï¼Œä»»ä½•è¿åæ³•å¾‹æ³•è§„ã€ä¾µçŠ¯ä»–äººåˆæ³•æƒç›Šçš„è¡Œä¸ºï¼Œå‡ä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ï¼Œåæœç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…ã€‚

2. ä½¿ç”¨æœŸé™

* æ‚¨åº”è¯¥åœ¨ä¸‹è½½ä¿å­˜ä½¿ç”¨æœ¬é¡¹ç›®çš„24å°æ—¶å†…ï¼Œåˆ é™¤æœ¬é¡¹ç›®çš„æºä»£ç å’Œç¨‹åºï¼›è¶…å‡ºæ­¤æœŸé™çš„ä»»ä½•ä½¿ç”¨è¡Œä¸ºï¼Œä¸€æ¦‚ä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ã€‚

3. æ“ä½œè§„èŒƒ

* æœ¬é¡¹ç›®ä»…å…è®¸åœ¨æˆæƒæƒ…å†µä¸‹ä½¿ç”¨æ•°æ®è®­ç»ƒï¼Œä¸¥ç¦ç”¨äºéæ³•ç›®çš„ï¼Œå¦åˆ™è‡ªè¡Œæ‰¿æ‹…æ‰€æœ‰ç›¸å…³è´£ä»»ï¼›ç”¨æˆ·å¦‚å› è¿åæ­¤è§„å®šè€Œå¼•å‘çš„ä»»ä½•æ³•å¾‹è´£ä»»ï¼Œå°†ç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…ï¼Œä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ã€‚
* ä¸¥ç¦ç”¨äºçªƒå–ä»–äººéšç§ï¼Œä¸¥ç¦ç”¨äºçªƒå–ä»–äººéšç§ï¼Œä¸¥ç¦ç”¨äºçªƒå–ä»–äººéšç§ï¼Œå¦åˆ™è‡ªè¡Œæ‰¿æ‹…æ‰€æœ‰ç›¸å…³è´£ä»»ã€‚

4. å…è´£å£°æ˜æ¥å—

* ä¸‹è½½ã€ä¿å­˜ã€è¿›ä¸€æ­¥æµè§ˆæºä»£ç æˆ–è€…ä¸‹è½½å®‰è£…ã€ç¼–è¯‘ä½¿ç”¨æœ¬ç¨‹åºï¼Œè¡¨ç¤ºä½ åŒæ„æœ¬è­¦å‘Šï¼Œå¹¶æ‰¿è¯ºéµå®ˆå®ƒ;

5. ç¦æ­¢ç”¨äºéæ³•æµ‹è¯•æˆ–æ¸—é€

* ç¦æ­¢åˆ©ç”¨æœ¬é¡¹ç›®çš„ç›¸å…³æŠ€æœ¯ä»äº‹éæ³•æµ‹è¯•æˆ–æ¸—é€ï¼Œç¦æ­¢åˆ©ç”¨æœ¬é¡¹ç›®çš„ç›¸å…³ä»£ç æˆ–ç›¸å…³æŠ€æœ¯ä»äº‹ä»»ä½•éæ³•å·¥ä½œï¼Œå¦‚å› æ­¤äº§ç”Ÿçš„ä¸€åˆ‡ä¸è‰¯åæœä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ã€‚
* ä»»ä½•å› æ­¤äº§ç”Ÿçš„ä¸è‰¯åæœï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®æ³„éœ²ã€ç³»ç»Ÿç˜«ç—ªã€ä¾µçŠ¯éšç§ç­‰ï¼Œå‡ä¸æœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…æ— å…³ï¼Œè´£ä»»ç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…ã€‚

6. å…è´£å£°æ˜ä¿®æ”¹

* æœ¬å…è´£å£°æ˜å¯èƒ½æ ¹æ®é¡¹ç›®è¿è¡Œæƒ…å†µå’Œæ³•å¾‹æ³•è§„çš„å˜åŒ–è¿›è¡Œä¿®æ”¹å’Œè°ƒæ•´ã€‚ç”¨æˆ·åº”å®šæœŸæŸ¥é˜…æœ¬é¡µé¢ä»¥è·å–æœ€æ–°ç‰ˆæœ¬çš„å…è´£å£°æ˜ï¼Œä½¿ç”¨æœ¬é¡¹ç›®æ—¶åº”éµå®ˆæœ€æ–°ç‰ˆæœ¬çš„å…è´£å£°æ˜ã€‚

7. å…¶ä»–

* é™¤æœ¬å…è´£å£°æ˜è§„å®šå¤–ï¼Œç”¨æˆ·åœ¨ä½¿ç”¨æœ¬é¡¹ç›®è¿‡ç¨‹ä¸­åº”éµå®ˆç›¸å…³çš„æ³•å¾‹æ³•è§„å’Œé“å¾·è§„èŒƒã€‚å¯¹äºå› ç”¨æˆ·è¿åç›¸å…³è§„å®šè€Œå¼•å‘çš„ä»»ä½•çº çº·æˆ–æŸå¤±ï¼Œæœ¬é¡¹ç›®åŠå…¶å¼€å‘è€…ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

* è¯·ç”¨æˆ·æ…é‡é˜…è¯»å¹¶ç†è§£æœ¬å…è´£å£°æ˜çš„æ‰€æœ‰å†…å®¹ï¼Œç¡®ä¿åœ¨ä½¿ç”¨æœ¬é¡¹ç›®æ—¶ä¸¥æ ¼éµå®ˆç›¸å…³è§„å®šã€‚

</details>
è¯·ç”¨æˆ·æ…é‡é˜…è¯»å¹¶ç†è§£æœ¬å…è´£å£°æ˜çš„æ‰€æœ‰å†…å®¹ï¼Œç¡®ä¿åœ¨ä½¿ç”¨æœ¬é¡¹ç›®æ—¶ä¸¥æ ¼éµå®ˆç›¸å…³è§„å®šã€‚

<br>  
<br>  
<br>  

## â­ Star History
> [!TIP] 
> å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæˆ–è€…æ‚¨å…³æ³¨æœ¬é¡¹ç›®çš„æœªæ¥å‘å±•ï¼Œè¯·ç»™é¡¹ç›® Starï¼Œè°¢è°¢ 

<div align="center">

[![Star History Chart](https://api.star-history.com/svg?repos=xming521/WeClone&type=Date)](https://www.star-history.com/#xming521/WeClone&Date)

</div>


<div align="center"> å…‹éš†æˆ‘ä»¬ï¼Œä¿ç•™çµé­‚çš„èŠ¬èŠ³ </div>
